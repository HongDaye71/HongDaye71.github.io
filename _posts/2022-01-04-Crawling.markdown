---
layout: post
title:  Google PlayStore Review Crawling
date:   2022-01-04 15:01:35 +0300
image:  '/images/Crawling.png'
tags:   [Crawling]
---

# Python_Selenium을 사용한<br/>
# Google PlayStore Review Crawling<br/>

> 본 포스팅에서는 2022.01.04기준 GooglePalyStore의 Mytheraphy App리뷰를 크롤링하는 Python코드를 다룹니다.
___

### Selenium이란? <br/>
Selenium은 주로 웹이나 앱을 테스트하는데 이용하는 프레임워크로 webdriver라는 API를 통해 운영제체제 설치된 Chrome등의 브라우저를 제어하게 된다.<br/>


### Selenium설치방법 <br/>
- Jupyter or cmd등 사용 시 : pip install selenium<br/>
- Pycharm사용시 : Setting -> 플러스버튼 클릭 -> Selenium검색 후 다운로드<br/>


### Crawling을 위해 필요한 설치항목 <br/>
- 라이브러리 : 방법에 따라 다양한 라이브러리가 사용될 수 있으나, 해당 포스팅에서는 Selenium, Pandas(데이터 정리용)를 사용한다.<br/>

- 드라이버 : Chrome, Explorer 등 브라우저 드라이버 (Selenium을 사용한 웹 자동화를 하기위해 필요하며 본인이 사용하는 브라우저 버전에 맞는 드라이버를 설치하면 됨)


### SourceCode <br/>
1. 라이브러리 임포트 및 변수선언 <br/>

```python
import pandas as pd
import time
from selenium import webdriver
viewmore = 0
```

2. Pandas Data Framework Setting <br/>

```python
pd.set_option('display.max_rows', 100) 
data = pd.DataFrame(data=[], columns=['아이디','리뷰','별점','날짜'])
```

3. selenium의 webdriver로 crawling할 페이지 열기 :<br/>
- 크롬 드라이버 설치방법 : https://chancoding.tistory.com/136<br/>
- XPath : F12 -> 상단 '상자 안 마우스 아이콘' 클릭-> 리뷰 모두보기 클릭하여 해당 버튼이 작성된 소스코드 확인 -> 마우스 우클릭 -> Copy -> Copy xpath

```python
driver = webdriver.Chrome(executable_path='C:/Users/ghdek/Desktop/chromedriver') #브라우저 드라이버 설치경로 입력 
driver.get('https://play.google.com/store/apps/details?id=eu.smartpatient.mytherapy&hl=ko&gl=US') #크롤링 할 페이지 주소
driver.find_element_by_xpath('//*[@id="fcxH9b"]/div[4]/c-wiz/div/div[2]/div/div/main/div/div[1]/div[6]/div/span/span').click() #첫 화면에는 4개의 리뷰만이 보이므로 Selenium을 사용해 '리뷰 모두보기'버튼클릭 
```

4. Scroll down <br/>

```python
while True:
    # 끝까지 스크롤 다운
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    last_height = driver.execute_script("return document.body.scrollHeight")
    # 1초 대기
    time.sleep(1)
    # 스크롤 높이를 다시 가져옴
    new_height = driver.execute_script("return document.body.scrollHeight")
    
    # 스크롤이 끝까지 내려간 경우 : 
    # 해당 어플의 경우, 리뷰의 수가 많아 스크롤다운 반복을 통해 모든 리뷰를 확인할 수 없음(더보기버튼 클릭필요)
    if new_height == last_height :
        #break
        time.sleep(1)
        driver.find_element_by_xpath('//*[@id="fcxH9b"]/div[4]/c-wiz/div/div[2]/div/div/main/div/div[1]/div[2]/div[2]/div/span/span').click()
        viewmore += 1
    if new_height == last_height and viewmore == 3 :
        time.sleep(1)
        viewmore += 1
    # 더보기 버튼을 세번 클릭하면, 모든 리뷰가 확인되므로 스크롤 종료 후 크롤링
    if new_height == last_height and viewmore == 4 :
        # 스크롤 다운 후 크롤링해야 인덱스 오류가 발생하지 않음 (크롤링 할 리뷰개수는 crawl 세번째 parameter에 입력)
        data = crawl(driver,data, 200)
        break

#스크롤 다운 시 페이지 새로고침
driver.get('https://play.google.com/store/apps/details?id=eu.smartpatient.mytherapy&hl=ko&gl=US&showAllReviews=true')
```

4. 어플 이름, 아이디, 리뷰, 별점, 날짜 수집 <br/>

```python
def crawl(driver, data, k):
    user_names = driver.find_elements_by_css_selector('.X43Kjb') #괄호 안에는 Class name입력
    reviews = driver.find_elements_by_css_selector('.UD7Dzf')
    star_grades = driver.find_elements_by_xpath('//div[@class="pf5lIe"]/div[@role="img"]')
    dates = driver.find_elements_by_css_selector('.p2TkOb')
    
    for i in range(k):
        tmp = []
        tmp.append(user_names[i].text)
        tmp.append(reviews[i].text)
        tmp.append(star_grades[i].get_attribute('aria-label'))
        tmp.append(dates[i].text)
        
        # 수집한 1명의 리뷰를 결과 프레임에 추가
        tmp = pd.DataFrame(data=[tmp], columns=data.columns)
        data = pd.concat([data,tmp])
    print("리뷰 크롤링 완료")
    return data

    # 인덱스 번호가 0으로 반복되지 않도록 새로운 인덱스 할당
    data.reset_index(inplace=True, drop=True)
```

5. 데이터를 엑셀파일로 저장<br/>

```python
data.to_excel('MyTherapy_review.xlsx')
```
